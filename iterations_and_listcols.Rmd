---
title: "writing_functions"
output: github_document
---

```{r}
library(tidyverse)
library(rvest)


knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Make a list

```{r}
l = 
  list(
    vec_numeric = 1:23,
    char_vec = c("Vaidehi"),
    mat = matrix(1:8, nrow = 2, ncol = 4),
    summary = summary(rnorm(1000, mean = 4))
  )

l[[1]] # first vector

l[["vec_numeric"]] # gives this vector
```

```{r}
list_normals = 
  list(
    a = rnorm(30, mean = 3, sd = 1),
    b = rnorm(30, mean = 30, sd = 1),
    c = rnorm(30, mean = 3, sd = 10),
    d = rnorm(30, mean = -3, sd = 4)
  )
```


copy and past function from last time
```{r}
mean_and_sd = function(x) {
  
  if(!is.numeric(x)) {
    stop("The input x should be numeric")
  }
  
  if(length(x)<5) {
    stop("only compute z scores when the input has 5 or more numbers")
  }
  
  mean_x = mean(x, na.rm = TRUE) # these are things that get returned
  sd_x = sd(x, na.rm = TRUE) # these are things that get returned
  
  tibble(
    mean_x, sd_x
    )
}
```


```{r}
mean_and_sd(list_normals[[1]])
mean_and_sd(list_normals[[2]])
mean_and_sd(list_normals[[3]])
mean_and_sd(list_normals[[4]])
```


Use a loop to iterate!

```{r}
output = vector("list", length = 4) # list with 4 spots to put your output

for (i in 1:4) {
  output[[i]] = mean_and_sd(list_normals[[i]])
}

output
```


Most of the time we use map to do the same thing
Map - don't have to set length of the output

```{r}
output = map(list_normals, mean_and_sd)
output = map(list_normals, median) # median is the function
output = map(list_normals, IQR) # IQR is the function
```

Map variants
```{r}
map_dfr(list_normals, mean_and_sd, .id = "sample") # id sample - telling R to keep the id from the input and makes it a dataframe

map_dbl(list_normals, mean_and_sd) # gives only single number
```


## List columns

Try to put my list into a dataframe
```{r}
listcol_df = 
  tibble(
    name = c("a", "b", "c", "d"),
    sample = list_normals
  )
```


Did this really work??

```{r}
pull(listcol_df, sample)
pull(listcol_df, name)
```


can I apply mean_and_sd?

```{r}
mean_and_sd(pull(listcol_df, sample)[[1]])
mean_and_sd(pull(listcol_df, sample)[[2]])
mean_and_sd(pull(listcol_df, sample)[[3]])
mean_and_sd(pull(listcol_df, sample)[[4]])

```


can iterate using map

```{r}
map(pull(listcol_df, sample), mean_and_sd)
```


adding a column ... for the output

```{r}
listcol_df = 
  listcol_df |> 
  mutate(
    summary = map(sample, mean_and_sd)
  )

pull(listcol_df, summary)
```

```{r}
listcol_df |> 
  select(-sample) |> 
  unnest(summary)
```


## Revisit NSDUH

```{r}
nsduh_url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"


nsduh_import = function(html, table_num){
  
  
  data = 
  html |> 
  html_table() |> 
  nth(table_num) |>
  slice(-1) |> 
  select(-contains("P Value")) |>
  pivot_longer(
    -State,
    names_to = "age_year", 
    values_to = "percent") |>
  separate(age_year, into = c("age", "year"), sep = "\\(") |>
  mutate(
    year = str_replace(year, "\\)", ""),
    percent = str_replace(percent, "[a-c]$", ""),
    percent = as.numeric(percent)) |>
  filter(!(State %in% c("Total U.S.", "Northeast", "Midwest", "South", "West")))
  
}

nsduh_import(nsduh_html, table_num = 1)
nsduh_import(nsduh_html, table_num = 2)
nsduh_import(nsduh_html, table_num = 3)
```

DO this with for loop

```{r}
output = vector("list", length = 3)

for (i in 1:3){
  output[[i]] = nsduh_import(html = nsduh_html, i)
}
```

Do this with map, but output vector is floating around

```{r}
map(1:3, nsduh_import, html = nsduh_html)
```

do this all in a dataframe so output vector is not floating around
list of dataframes can be unnested. 

you imported tables you were interested in, and do any downstream analysis you are interested in for each of those tables

```{r}
nsduh_df = 
  tibble(
  name = c("marj year", "marj month", "marj first"),
  number = 1:3
  ) |> 
  mutate(
    table = map(number, nsduh_import, html = nsduh_html)
  ) |>
  unnest(table)
```


## look at weather data

```{r}
library(p8105.datasets)
data("weather_df")
```

```{r}
weather_df |> 
  filter(name == "CentralPark_NY") |> 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_point() +
  geom_smooth(method = "lm")
```

```{r}
weather_df |> 
  filter(name == "CentralPark_NY") |> 
  lm(tmax ~ tmin, data = _)


weather_df |> 
  filter(name == "Molokai_HI") |> 
  lm(tmax ~ tmin, data = _)

weather_df |> 
  filter(name == "Waterhole_WA") |> 
  lm(tmax ~ tmin, data = _)
```

Let's iterate differently...
```{r}
weather_nest = 
  weather_df |> 
  nest(data = date:tmin) # collapsing these columns in tibble
```


```{r}
lm(tmax ~ tmin, data = pull(weather_nest, data)[[1]])
lm(tmax ~ tmin, data = pull(weather_nest, data)[[2]])
lm(tmax ~ tmin, data = pull(weather_nest, data)[[3]])
```


can do the same thing with map
 writing funtion first
```{r}
weather_lm = function(df) {
  lm(tmax ~ tmin, data = df)
}
```

output is floating
```{r}
map(pull(weather_nest, data), weather_lm)
```

we want results of linear model next to dataset

```{r}
weather_nest |> 
  mutate(
    lm_fits = map(data, weather_lm)
  )
```


